{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Add imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import inception_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Setup gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Set paths to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_CSV = './data/train.csv'\n",
    "TRAIN_IMAGES_DIR = './data/train_images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load csv using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    800113bb65efe69e.jpg\n",
       "1    8002cb321f8bfcdf.jpg\n",
       "2    80070f7fb5e2ccaa.jpg\n",
       "3    80077517781fb94f.jpg\n",
       "4    800cbf0ff87721f8.jpg\n",
       "5    800edef467d27c15.jpg\n",
       "6    800f85dc5f407aef.jpg\n",
       "7    801d6dcd96e48ebc.jpg\n",
       "8    801f78399a44e7af.jpg\n",
       "9    8021b94d437eb7d3.jpg\n",
       "Name: image, dtype: object"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf = pd.read_csv(TRAIN_CSV, dtype=str)\n",
    "traindf['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load images using ImageDataGenerator, copied from [StackOverflow](https://stackoverflow.com/questions/59464409/loading-images-in-keras-for-cnn-from-directory-but-label-in-csv-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14906 validated image filenames belonging to 12 classes.\n",
      "Found 3726 validated image filenames belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "shape = (256, 256, 3)\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255., validation_split=0.2)\n",
    "train_generator = datagen.flow_from_dataframe(dataframe = traindf,\n",
    "                                              directory = TRAIN_IMAGES_DIR,\n",
    "                                              featurewise_std_normalization = True,\n",
    "                                              x_col = 'image',\n",
    "                                              y_col = 'labels',\n",
    "                                              subset = 'training',\n",
    "                                              batch_size = 32,\n",
    "                                              seed = 1,\n",
    "                                              shuffle = True,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              target_size = shape[:2]\n",
    "                                             )\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(dataframe = traindf,\n",
    "                                              directory = TRAIN_IMAGES_DIR,\n",
    "                                              featurewise_std_normalization = True,\n",
    "                                              x_col = 'image',\n",
    "                                              y_col = 'labels',\n",
    "                                              subset = 'validation',\n",
    "                                              batch_size = 32,\n",
    "                                              seed = 1,\n",
    "                                              shuffle = True,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              target_size = shape[:2]\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(iter(train_generator))\n",
    "val_images, val_labels = next(iter(validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classes_amount = len(set(train_generator.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### First model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 196608)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               25165952  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,167,500\n",
      "Trainable params: 25,167,500\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 21:56:22.254525: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "  [\n",
    "    keras.Input(shape=train_generator.image_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes), # now the size of the last layer is 12, not 14906, so everything fits\n",
    "  ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',#keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(train_generator, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_v3 (Functional)   (None, None, None, 2048)  21802784  \n",
      "                                                                 \n",
      " global_average_pooling2d_13  (None, 2048)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 12)                24588     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,827,372\n",
      "Trainable params: 24,588\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "imagenet = inception_v3.InceptionV3(weights ='imagenet', include_top = False)\n",
    "for layer in imagenet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model1 = keras.Sequential([\n",
    "    keras.Input(shape = train_generator.image_shape),\n",
    "    imagenet,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(classes_amount, kernel_initializer = 'uniform', activation = \"softmax\")\n",
    "])\n",
    "\n",
    "model1.compile(loss = 'categorical_crossentropy',\n",
    "               optimizer = 'Adam',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "466/466 [==============================] - 1610s 3s/step - loss: 1.2694 - accuracy: 0.5896\n",
      "Epoch 2/5\n",
      "466/466 [==============================] - 1594s 3s/step - loss: 1.0445 - accuracy: 0.6617\n",
      "Epoch 3/5\n",
      "466/466 [==============================] - 1596s 3s/step - loss: 0.9705 - accuracy: 0.6821\n",
      "Epoch 4/5\n",
      "466/466 [==============================] - 1620s 3s/step - loss: 0.9219 - accuracy: 0.6956\n",
      "Epoch 5/5\n",
      "466/466 [==============================] - 1604s 3s/step - loss: 0.8876 - accuracy: 0.7086\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(train_generator, \n",
    "                     epochs = 5,\n",
    "                     verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 00:19:51.771702: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/m1/assets\n"
     ]
    }
   ],
   "source": [
    "model1.save(f\"model/m1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_predictions = model1.predict(val_images)\n",
    "\n",
    "y_true = [np.argmax(row) for row in val_labels]\n",
    "y_pred = [np.argmax(row) for row in model_predictions]\n",
    "\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.imshow(matrix)\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate\n",
      "30/30 [==============================] - 102s 3s/step - loss: 2.4001 - accuracy: 0.1611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 2.400103807449341, 'accuracy': 0.1611170768737793}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Evaluate\")\n",
    "result = model1.evaluate(validation_generator)\n",
    "dict(zip(model1.metrics_names, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_32 (Sequential)  (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, None, None, 2048)  21802784  \n",
      "                                                                 \n",
      " global_average_pooling2d_19  (None, 2048)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 12)                24588     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,827,372\n",
      "Trainable params: 24,588\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "intercept_layer = inception_v3.InceptionV3(weights ='imagenet', include_top = False)\n",
    "for layer in intercept_layer.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "imput_layer = keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=shape),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "])\n",
    "    \n",
    "model2 = keras.Sequential([\n",
    "    imput_layer,\n",
    "    intercept_layer,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(classes_amount, kernel_initializer = 'uniform', activation = \"softmax\")\n",
    "])\n",
    "\n",
    "model2.compile(loss = 'categorical_crossentropy',\n",
    "               optimizer = 'Adam',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 [==============================] - 1599s 5s/step - loss: 1.4324 - accuracy: 0.5279 - val_loss: 1.0670 - val_accuracy: 0.5938\n",
      "INFO:tensorflow:Assets written to: model/m2/assets\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(train_generator, \n",
    "                     epochs = 1,\n",
    "                    validation_data = validation_data,\n",
    "                     verbose = 1)\n",
    "\n",
    "model2.save(f\"model/m2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate\n",
      "292/292 [==============================] - 2343s 8s/step - loss: 1.2721 - accuracy: 0.5989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.272117257118225, 'accuracy': 0.5988621711730957}"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Evaluate\")\n",
    "\n",
    "result = model2.evaluate(validation_generator)\n",
    "dict(zip(model2.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f80b61f5130>"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_predictions2 = model2.predict(val_images)\n",
    "\n",
    "y_true = [np.argmax(row) for row in val_labels]\n",
    "y_pred2 = [np.argmax(row) for row in model_predictions2]\n",
    "\n",
    "matrix = ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred2))\n",
    "\n",
    "matrix.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
