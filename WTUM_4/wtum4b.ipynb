{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Add imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow import keras\n",
    "from ast import literal_eval\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import inception_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Setup gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 20:49:28.596936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 20:49:28.626783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 20:49:28.626949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 20:49:28.679708: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-25 20:49:28.680956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 20:49:28.681188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 20:49:28.681359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 20:49:29.098318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 20:49:29.098484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 20:49:29.098615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 20:49:29.098712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4016 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Set paths to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_CSV = '../data/train.csv'\n",
    "TRAIN_IMAGES_DIR = '../data/train_images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load csv using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[scab]                                 4826\n[healthy]                              4624\n[frog_eye_leaf_spot]                   3181\n[rust]                                 1860\n[complex]                              1602\n[powdery_mildew]                       1184\n[scab, frog_eye_leaf_spot]              686\n[scab, frog_eye_leaf_spot, complex]     200\n[frog_eye_leaf_spot, complex]           165\n[rust, frog_eye_leaf_spot]              120\n[rust, complex]                          97\n[powdery_mildew, complex]                87\nName: labels, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf = pd.read_csv(TRAIN_CSV, dtype=str)\n",
    "traindf['labels'] = traindf['labels'].str.split()\n",
    "traindf\n",
    "traindf['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                      image                               labels\n0      800113bb65efe69e.jpg                            [healthy]\n1      8002cb321f8bfcdf.jpg  [scab, frog_eye_leaf_spot, complex]\n2      80070f7fb5e2ccaa.jpg                               [scab]\n3      80077517781fb94f.jpg                               [scab]\n4      800cbf0ff87721f8.jpg                            [complex]\n...                     ...                                  ...\n18627  fffb900a92289a33.jpg                            [healthy]\n18628  fffc488fa4c0e80c.jpg                               [scab]\n18629  fffc94e092a59086.jpg                               [rust]\n18630  fffe105cf6808292.jpg           [scab, frog_eye_leaf_spot]\n18631  fffe472a0001bd25.jpg                            [healthy]\n\n[18632 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>800113bb65efe69e.jpg</td>\n      <td>[healthy]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8002cb321f8bfcdf.jpg</td>\n      <td>[scab, frog_eye_leaf_spot, complex]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>80070f7fb5e2ccaa.jpg</td>\n      <td>[scab]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>80077517781fb94f.jpg</td>\n      <td>[scab]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>800cbf0ff87721f8.jpg</td>\n      <td>[complex]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18627</th>\n      <td>fffb900a92289a33.jpg</td>\n      <td>[healthy]</td>\n    </tr>\n    <tr>\n      <th>18628</th>\n      <td>fffc488fa4c0e80c.jpg</td>\n      <td>[scab]</td>\n    </tr>\n    <tr>\n      <th>18629</th>\n      <td>fffc94e092a59086.jpg</td>\n      <td>[rust]</td>\n    </tr>\n    <tr>\n      <th>18630</th>\n      <td>fffe105cf6808292.jpg</td>\n      <td>[scab, frog_eye_leaf_spot]</td>\n    </tr>\n    <tr>\n      <th>18631</th>\n      <td>fffe472a0001bd25.jpg</td>\n      <td>[healthy]</td>\n    </tr>\n  </tbody>\n</table>\n<p>18632 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load images using ImageDataGenerator, copied from [StackOverflow](https://stackoverflow.com/questions/59464409/loading-images-in-keras-for-cnn-from-directory-but-label-in-csv-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14906 validated image filenames belonging to 6 classes.\n",
      "Found 3726 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "shape = (224, 224, 3)\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255., validation_split=0.2)\n",
    "train_generator = datagen.flow_from_dataframe(dataframe = traindf,\n",
    "                                              directory = TRAIN_IMAGES_DIR,\n",
    "                                              featurewise_std_normalization = True,\n",
    "                                              x_col = 'image',\n",
    "                                              y_col = 'labels',\n",
    "                                              subset = 'training',\n",
    "                                              batch_size = 32,\n",
    "                                              seed = 1,\n",
    "                                              shuffle = True,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              target_size = shape[:2]\n",
    "                                             )\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(dataframe = traindf,\n",
    "                                              directory = TRAIN_IMAGES_DIR,\n",
    "                                              featurewise_std_normalization = True,\n",
    "                                              x_col = 'image',\n",
    "                                              y_col = 'labels',\n",
    "                                              subset = 'validation',\n",
    "                                              batch_size = 32,\n",
    "                                              seed = 1,\n",
    "                                              shuffle = True,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              target_size = shape[:2]\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_images, train_labels = next(iter(train_generator))\n",
    "val_images, val_labels = next(iter(validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classes_amount = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Third model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, None, None, 2048)  21802784  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 12294     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,815,078\n",
      "Trainable params: 12,294\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "intercept_layer = inception_v3.InceptionV3(weights ='imagenet', include_top = False)\n",
    "for layer in intercept_layer.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "imput_layer = keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=shape),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "])\n",
    "    \n",
    "model2 = keras.Sequential([\n",
    "    imput_layer,\n",
    "    intercept_layer,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(classes_amount, kernel_initializer = 'uniform', activation = \"softmax\")\n",
    "])\n",
    "\n",
    "model2.compile(loss = 'categorical_crossentropy',\n",
    "               optimizer = 'Adam',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 20:49:46.894796: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-05-25 20:49:47.401227: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/466 [..............................] - ETA: 1:05:40 - loss: 2.1782 - accuracy: 0.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 20:49:48.569165: W tensorflow/core/common_runtime/bfc_allocator.cc:360] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466/466 [==============================] - 1728s 4s/step - loss: 1.3131 - accuracy: 0.5475 - val_loss: 1.1740 - val_accuracy: 0.5888\n",
      "Epoch 2/5\n",
      "466/466 [==============================] - 1701s 4s/step - loss: 1.1423 - accuracy: 0.6200 - val_loss: 1.0373 - val_accuracy: 0.6559\n",
      "Epoch 3/5\n",
      "466/466 [==============================] - 1689s 4s/step - loss: 1.1168 - accuracy: 0.6329 - val_loss: 1.3044 - val_accuracy: 0.5368\n",
      "Epoch 4/5\n",
      "466/466 [==============================] - 1701s 4s/step - loss: 1.0824 - accuracy: 0.6466 - val_loss: 1.0392 - val_accuracy: 0.6498\n",
      "Epoch 5/5\n",
      "466/466 [==============================] - 1656s 4s/step - loss: 1.0834 - accuracy: 0.6460 - val_loss: 1.0585 - val_accuracy: 0.6428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/m2.5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/m2.5/assets\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(train_generator, \n",
    "                     epochs = 5,\n",
    "                    validation_data = validation_generator,\n",
    "                     verbose = 1)\n",
    "\n",
    "model2.save(f\"model/m2.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate\n",
      "117/117 [==============================] - 326s 3s/step - loss: 1.0585 - accuracy: 0.6428\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'loss': 1.058523178100586, 'accuracy': 0.6427804827690125}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Evaluate\")\n",
    "\n",
    "result = model2.evaluate(validation_generator)\n",
    "dict(zip(model2.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f03afc18910>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_predictions2 = model2.predict(val_images)\n",
    "\n",
    "y_true = [np.argmax(row) for row in val_labels]\n",
    "y_pred2 = [np.argmax(row) for row in model_predictions2]\n",
    "\n",
    "matrix = ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred2))\n",
    "\n",
    "matrix.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}