{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Add imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow import keras\n",
    "from ast import literal_eval\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import inception_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Setup gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 23:51:44.067511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 23:51:44.095265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 23:51:44.095430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 23:51:44.096135: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-25 23:51:44.096909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 23:51:44.097070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 23:51:44.097189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 23:51:44.622670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 23:51:44.622853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 23:51:44.622986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 23:51:44.623084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3961 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Set paths to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_CSV = '../data/train.csv'\n",
    "TRAIN_IMAGES_DIR = '../data/train_images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load csv using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[scab]                                 4826\n[healthy]                              4624\n[frog_eye_leaf_spot]                   3181\n[rust]                                 1860\n[complex]                              1602\n[powdery_mildew]                       1184\n[scab, frog_eye_leaf_spot]              686\n[scab, frog_eye_leaf_spot, complex]     200\n[frog_eye_leaf_spot, complex]           165\n[rust, frog_eye_leaf_spot]              120\n[rust, complex]                          97\n[powdery_mildew, complex]                87\nName: labels, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf = pd.read_csv(TRAIN_CSV, dtype=str)\n",
    "traindf['labels'] = traindf['labels'].str.split()\n",
    "traindf\n",
    "traindf['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                      image                               labels\n0      800113bb65efe69e.jpg                            [healthy]\n1      8002cb321f8bfcdf.jpg  [scab, frog_eye_leaf_spot, complex]\n2      80070f7fb5e2ccaa.jpg                               [scab]\n3      80077517781fb94f.jpg                               [scab]\n4      800cbf0ff87721f8.jpg                            [complex]\n...                     ...                                  ...\n18627  fffb900a92289a33.jpg                            [healthy]\n18628  fffc488fa4c0e80c.jpg                               [scab]\n18629  fffc94e092a59086.jpg                               [rust]\n18630  fffe105cf6808292.jpg           [scab, frog_eye_leaf_spot]\n18631  fffe472a0001bd25.jpg                            [healthy]\n\n[18632 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>800113bb65efe69e.jpg</td>\n      <td>[healthy]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8002cb321f8bfcdf.jpg</td>\n      <td>[scab, frog_eye_leaf_spot, complex]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>80070f7fb5e2ccaa.jpg</td>\n      <td>[scab]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>80077517781fb94f.jpg</td>\n      <td>[scab]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>800cbf0ff87721f8.jpg</td>\n      <td>[complex]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18627</th>\n      <td>fffb900a92289a33.jpg</td>\n      <td>[healthy]</td>\n    </tr>\n    <tr>\n      <th>18628</th>\n      <td>fffc488fa4c0e80c.jpg</td>\n      <td>[scab]</td>\n    </tr>\n    <tr>\n      <th>18629</th>\n      <td>fffc94e092a59086.jpg</td>\n      <td>[rust]</td>\n    </tr>\n    <tr>\n      <th>18630</th>\n      <td>fffe105cf6808292.jpg</td>\n      <td>[scab, frog_eye_leaf_spot]</td>\n    </tr>\n    <tr>\n      <th>18631</th>\n      <td>fffe472a0001bd25.jpg</td>\n      <td>[healthy]</td>\n    </tr>\n  </tbody>\n</table>\n<p>18632 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load images using ImageDataGenerator, copied from [StackOverflow](https://stackoverflow.com/questions/59464409/loading-images-in-keras-for-cnn-from-directory-but-label-in-csv-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14906 validated image filenames belonging to 6 classes.\n",
      "Found 3726 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "shape = (224, 224, 3)\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255., validation_split=0.2)\n",
    "train_generator = datagen.flow_from_dataframe(dataframe = traindf,\n",
    "                                              directory = TRAIN_IMAGES_DIR,\n",
    "                                              featurewise_std_normalization = True,\n",
    "                                              x_col = 'image',\n",
    "                                              y_col = 'labels',\n",
    "                                              subset = 'training',\n",
    "                                              batch_size = 32,\n",
    "                                              seed = 1,\n",
    "                                              shuffle = True,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              target_size = shape[:2]\n",
    "                                             )\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(dataframe = traindf,\n",
    "                                              directory = TRAIN_IMAGES_DIR,\n",
    "                                              featurewise_std_normalization = True,\n",
    "                                              x_col = 'image',\n",
    "                                              y_col = 'labels',\n",
    "                                              subset = 'validation',\n",
    "                                              batch_size = 32,\n",
    "                                              seed = 1,\n",
    "                                              shuffle = True,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              target_size = shape[:2]\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_images, train_labels = next(iter(train_generator))\n",
    "val_images, val_labels = next(iter(validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classes_amount = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Third model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, None, None, 2048)  21802784  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 12294     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,815,078\n",
      "Trainable params: 12,294\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "intercept_layer = inception_v3.InceptionV3(weights ='imagenet', include_top = False)\n",
    "for layer in intercept_layer.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "imput_layer = keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=shape),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "])\n",
    "    \n",
    "model2 = keras.Sequential([\n",
    "    imput_layer,\n",
    "    intercept_layer,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(classes_amount, kernel_initializer = 'uniform', activation = \"softmax\")\n",
    "])\n",
    "\n",
    "model2.compile(loss = 'categorical_crossentropy',\n",
    "               optimizer = 'rmsprop',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 23:52:02.598887: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-05-25 23:52:03.133846: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/466 [..............................] - ETA: 1:06:53 - loss: 1.9684 - accuracy: 0.1562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 23:52:04.305469: W tensorflow/core/common_runtime/bfc_allocator.cc:360] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466/466 [==============================] - 1694s 4s/step - loss: 1.3464 - accuracy: 0.5331 - val_loss: 1.3300 - val_accuracy: 0.5274\n",
      "Epoch 2/5\n",
      "466/466 [==============================] - 1675s 4s/step - loss: 1.1869 - accuracy: 0.6040 - val_loss: 1.0464 - val_accuracy: 0.6573\n",
      "Epoch 3/5\n",
      "466/466 [==============================] - 1650s 4s/step - loss: 1.1405 - accuracy: 0.6203 - val_loss: 1.0652 - val_accuracy: 0.6527\n",
      "Epoch 4/5\n",
      "466/466 [==============================] - 1666s 4s/step - loss: 1.1105 - accuracy: 0.6392 - val_loss: 1.3485 - val_accuracy: 0.5539\n",
      "Epoch 5/5\n",
      "466/466 [==============================] - 1714s 4s/step - loss: 1.1015 - accuracy: 0.6385 - val_loss: 1.0259 - val_accuracy: 0.6608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/m2.6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/m2.6/assets\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(train_generator, \n",
    "                     epochs = 5,\n",
    "                    validation_data = validation_generator,\n",
    "                     verbose = 1)\n",
    "\n",
    "model2.save(f\"model/m2.6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate\n",
      "117/117 [==============================] - 328s 3s/step - loss: 1.0259 - accuracy: 0.6608\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'loss': 1.0258911848068237, 'accuracy': 0.6607621908187866}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Evaluate\")\n",
    "\n",
    "result = model2.evaluate(validation_generator)\n",
    "dict(zip(model2.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f52accebfd0>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_predictions2 = model2.predict(val_images)\n",
    "\n",
    "y_true = [np.argmax(row) for row in val_labels]\n",
    "y_pred2 = [np.argmax(row) for row in model_predictions2]\n",
    "\n",
    "matrix = ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred2))\n",
    "\n",
    "matrix.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}